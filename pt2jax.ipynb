{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dm-haiku in ./lib/python3.10/site-packages (0.0.12)\n",
      "Requirement already satisfied: einops in ./lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in ./lib/python3.10/site-packages (from dm-haiku) (2.1.0)\n",
      "Requirement already satisfied: jmp>=0.0.2 in ./lib/python3.10/site-packages (from dm-haiku) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./lib/python3.10/site-packages (from dm-haiku) (1.26.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./lib/python3.10/site-packages (from dm-haiku) (0.9.0)\n",
      "Requirement already satisfied: flax>=0.7.1 in ./lib/python3.10/site-packages (from dm-haiku) (0.8.2)\n",
      "Requirement already satisfied: jax>=0.4.19 in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (0.4.26)\n",
      "Requirement already satisfied: msgpack in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (1.0.8)\n",
      "Requirement already satisfied: optax in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (0.2.2)\n",
      "Requirement already satisfied: orbax-checkpoint in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (0.5.9)\n",
      "Requirement already satisfied: tensorstore in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (0.1.56)\n",
      "Requirement already satisfied: rich>=11.1 in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (4.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./lib/python3.10/site-packages (from flax>=0.7.1->dm-haiku) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in ./lib/python3.10/site-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum in ./lib/python3.10/site-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in ./lib/python3.10/site-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (1.13.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./lib/python3.10/site-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (2.16.1)\n",
      "Requirement already satisfied: chex>=0.1.86 in ./lib/python3.10/site-packages (from optax->flax>=0.7.1->dm-haiku) (0.1.86)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in ./lib/python3.10/site-packages (from optax->flax>=0.7.1->dm-haiku) (0.4.26)\n",
      "Requirement already satisfied: etils[epath,epy] in ./lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.7.0)\n",
      "Requirement already satisfied: nest_asyncio in ./lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.5.8)\n",
      "Requirement already satisfied: protobuf in ./lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (5.26.1)\n",
      "Requirement already satisfied: toolz>=0.9.0 in ./lib/python3.10/site-packages (from chex>=0.1.86->optax->flax>=0.7.1->dm-haiku) (0.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.1->dm-haiku) (0.1.2)\n",
      "Requirement already satisfied: fsspec in ./lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (2023.9.2)\n",
      "Requirement already satisfied: importlib_resources in ./lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (6.4.0)\n",
      "Requirement already satisfied: zipp in ./lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (3.18.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dm-haiku einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, torch\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from einops import rearrange, reduce, repeat, einsum\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = hk.PRNGSequence(0)\n",
    "nk = lambda : next(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 8\n",
    "torch.set_printoptions(precision=precision)\n",
    "jnp.set_printoptions(precision=precision)\n",
    "np.set_printoptions(precision=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haiku\n",
    "def forward(args, x):\n",
    "    wq = hk.Linear(args.dim, with_bias=False, name='wq')\n",
    "    wk = hk.Linear(args.dim, with_bias=False, name='wk')\n",
    "    wv = hk.Linear(args.dim, with_bias=False, name='wv')\n",
    "    wo = hk.Linear(args.dim, with_bias=False, name='wo') \n",
    "\n",
    "    q, k, v = map(lambda x: rearrange(x, 'l (nh dh) -> nh l dh', nh=args.n_head), (wq(x), wk(x), wv(x)))\n",
    "\n",
    "    scores = einsum(q, k, 'h i k, h j k -> h i j')\n",
    "\n",
    "    heads = scores @ v  # ignoring sfmx now\n",
    "\n",
    "    return wo(rearrange(heads, 'nh l dh -> l (nh dh)', nh=args.n_head))\n",
    "\n",
    "\n",
    "# torch\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.wq, self.wk, self.wv, self.wo = (nn.Linear(args.dim, args.dim, bias=False) for _ in range(4))      \n",
    "\n",
    "    def forward(self, x):\n",
    "        args = self.args\n",
    "\n",
    "        q, k, v = map(lambda x: rearrange(x, 'l (nh dh) -> nh l dh', nh=args.n_head), (self.wq(x), self.wk(x), self.wv(x)))\n",
    "\n",
    "        scores = einsum(q, k, 'h i k, h j k -> h i j')\n",
    "\n",
    "        heads = scores @ v\n",
    "\n",
    "        return self.wo(rearrange(heads, 'nh l dh -> l (nh dh)', nh=args.n_head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    dim: int\n",
    "    n_head: int\n",
    "\n",
    "\n",
    "args = Args(dim=4096, n_head=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "x_ = torch.randn(seq_len, args.dim)\n",
    "x = jnp.asarray(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = hk.transform(partial(forward, args))\n",
    "\n",
    "params = attention.init(nk(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_ = Attention(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['wq']['w'] = jnp.asarray(attention_.wq.weight.data.T)\n",
    "params['wk']['w'] = jnp.asarray(attention_.wk.weight.data.T)\n",
    "params['wv']['w'] = jnp.asarray(attention_.wv.weight.data.T)\n",
    "params['wo']['w'] = jnp.asarray(attention_.wo.weight.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_out = attention.apply(params, nk(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pt_out = attention_(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.620579     0.2395443   14.827803   ...  -4.097179     5.0579653\n",
      "   -0.06813204]\n",
      " [ -2.9569612    6.4783435    1.6496208  ...   4.478825    11.532101\n",
      "    4.6816864 ]\n",
      " [ -1.0786729    0.5392799    6.2966537  ...  -3.1048808   -7.515436\n",
      "   13.741988  ]\n",
      " ...\n",
      " [-20.14898      2.7913113   -1.4063245  ...  20.23688    -15.4071665\n",
      "    2.8805785 ]\n",
      " [  9.724804    -5.035846     7.1828976  ...  -6.987926   -11.659335\n",
      "   -4.3041105 ]\n",
      " [ -2.7573986    2.9879174    7.2161365  ...   8.685687    -8.505831\n",
      "   -3.262116  ]]\n",
      "tensor([[-10.62058258,   0.23952192,  14.82778645,  ...,  -4.09717321,\n",
      "           5.05792522,  -0.06814072],\n",
      "        [ -2.95696282,   6.47835493,   1.64962208,  ...,   4.47883129,\n",
      "          11.53208637,   4.68168831],\n",
      "        [ -1.07867491,   0.53928685,   6.29667091,  ...,  -3.10488224,\n",
      "          -7.51543188,  13.74200153],\n",
      "        ...,\n",
      "        [-20.14899254,   2.79131079,  -1.40632212,  ...,  20.23687744,\n",
      "         -15.40716171,   2.88055515],\n",
      "        [  9.72478390,  -5.03583384,   7.18287897,  ...,  -6.98794365,\n",
      "         -11.65935040,  -4.30408287],\n",
      "        [ -2.75737786,   2.98791552,   7.21613598,  ...,   8.68564892,\n",
      "          -8.50583267,  -3.26212120]])\n"
     ]
    }
   ],
   "source": [
    "print(jax_out)\n",
    "print(pt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(False, dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(jax_out, jnp.asarray(pt_out), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
